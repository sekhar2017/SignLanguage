# SignLanguage

In this Project I have tried to Make a Model for American Sign Language . The Image Consists of more than 12000 images of 24 Images. The letter 'j' and 'z' are not included as they require motion. The Cross Validation and Test accuracy both are More than 90%! However, I have not tested it on other subjects' images. So more images will lead to better generalization. It is a primary step for this project. Hopefully people will use ML and DL more for such purpose. 

As for algorithm, it is simple. I have used Transfer learning on Google's inception model. Nothing else. 

The dataset I have used is of only user from http://empslocal.ex.ac.uk/people/staff/np331/index.php?section=FingerSpellingDataset . The more user images are included , the better

![alt text](https://raw.githubusercontent.com/sezan92/SignLanguage/master/ASL.png)
